* mokuroku
** Implementation
*** Development
**** DONE Read papers on secondary index strategies
***** DONE Diff-Index: Differentiated Index in Distributed Log-Structured Data Stores
****** Diff-Index stores the primary key after the index key
****** Diff-Index assumes index value is the same as the base value
***** DONE Efficient Secondary Attribute Lookup in NoSQL Databases
****** their embedded index requires modifying LevelDB internal structures
****** like Diff-Index, assumes index values match readily available data attributes
****** overall performance of "lazy updates" on a stand-alone index is as good as it gets
****** performance of lazy updates is very good with read-heavy workloads
***** DONE Comparative Study of Secondary Indexing Techniques in LSM-based NoSQL Databases
****** composite index performs well most of the time
***** c.f. http://dblab.cs.ucr.edu/projects/KeyValueIndexes/
**** TODO Update stale index entries on =put()= and =delete()=
***** both =put= and =delete= are the same thing: old index values are stale
***** timestamp vs sequence number
****** Comparative Study paper uses the LevelDB "sequence number" feature for time ordering
****** rust-rocksdb does not yet expose this feature of RocksDB
***** on update, store primary key in ~mrview--changes~ cf with timestamp value
****** ts would be nanos since epoch, a 16 byte value
****** =let ts: u128 = SystemTime.duration_since(std::time::UNIX_EPOCH)?.as_nanos();=
***** on query, perform compaction of updated entries based on timestamp
****** Cassandra does a "read repair" which prunes stale entries on query
***** Diff-Index paper adds index updates to a queue, processes in background
***** perhaps maintain a bloom/cuckoo filter of updated primary keys
****** https://github.com/seiflotfy/rust-cuckoofilter
****** https://github.com/nervosnetwork/bloom-filters
****** https://github.com/sagalasan/bloom-filter
****** on startup, scan ~mrview--changes~ to get prime the bloom filter
***** on =query()= the iterator will detect and remove stale entries
**** TODO Write the index key/value pairs received in =put()= using a =WriteBatch=
***** probably should batch up for each column family (index)
**** TODO Write a test that rebuilds the index
**** TODO Add function to delete an index
***** remove corresponding entry from =views= list
**** TODO Clean up stale indices
***** Called by the application in an ad hoc fashion
***** Delete any column families with our prefix that do not match any registered view
**** TODO Support the =rocksdb::WriteBatch= atomic commit feature
**** TODO Using some assumed key/value sizes, compute the overhead of the index, add to README
**** TODO Consider using the KMP algorithm to find the index key separator
***** c.f. https://en.wikipedia.org/wiki/Knuth–Morris–Pratt_algorithm
**** TODO Support query with start and end key values/prefixes
**** TODO Support query options to skip some number of results, limit to some number
**** TODO Consider options for thread safe operations
*** Publishing
**** DONE Write a guide on how to use properly
***** Define views at time of DB open
***** Prime the indices at startup to improve response time
**** DONE Start a changelog
**** DONE Write API documentation at the module level
***** assumes we already wrote function-level documentation
**** DONE Write a quick example for the =README.md=
**** DONE Write a simple example crate in =examples= directory
**** DONE Populate =Cargo.toml= with useful meta information
**** DONE Push to GitHub
**** DONE Publish to crates.io
**** TODO README should have bullet point feature list
***** bring-your-own-format for keys and values
***** emit zero or more index key and values of your design per data record
***** leverage the serialization you are already using with RocksDB
**** TODO Give an example of how to merge query results a la tanuki tags
**** DONE Add references to the research papers
*** Further Work
**** TODO Read the LSM key/value stores research paper on secondary index algorithms
***** Has various approaches to implementing indices
**** TODO Support some form of "reduce" operation, like PouchDB
** Alternative Databases
*** [[https://github.com/spacejam/sled][sled]] is similar to RocksDB, written in Rust
**** would use their ~keyspace~ in place of column families
