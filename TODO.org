* mokuroku
** Design
*** Usage
**** Client creates the =RocksDB= instance, passes to index functions
**** All operations must go through index functions (put, delete, etc)
**** Register view definitions to provide index keys and values
**** Query on the index with or without keys for filtering the results
**** Functions to build the index as needed, such as for existing data
*** Data Model
**** Database keys and values are defined by the application
***** i.e. library does not dictate any particular format or key prefix
**** Indices are named (e.g. "etags") by the application
**** Index key consists of a prefix from the app plus a unique suffix
***** Because the app may output non-unique values, the key must be made unique
***** Suffix needs to be sufficiently unique even if many records are written in a short time
**** App outputs additional data as the value for the index row
***** Application provides a mapping function to provide index keys and values
***** In addition to the key, the mapping function also emits other data
***** A single invocation of the mapping function may emit multiple rows of data
**** Specifying a ~reduce~ function means index rows consist of key and value is reduce output
***** e.g. ~count~ would result in key from map output and value from reduce output
***** e.g. [('foo', 12), ('bar', 4), ('quux', 101)]
**** Indices must be namespaced to avoid collision with application data
***** RocksDB supports column families for this purpose
**** Querying index employs the RocksDB key prefix iterator
***** Consequently the query operation returns an iterator
***** Results returned are the data from the mapping function
***** RocksDB can quickly scan to a key prefix to start iterating
**** When querying mulitple keys, results are returned in the given key order
*** References
**** https://misfra.me/2017/01/18/how-to-implement-secondary-indexes/
***** index key is the information you're searching for, value is the original key
***** important to keep the keys unique and canonically formed
**** RocksDB FAQ seems to suggest using column families for different "key spaces"
***** c.f. https://github.com/facebook/rocksdb/wiki/Column-Families
** Implementation
*** Indices are stored in separate column families
**** Name consists of our special prefix (e.g. =mrview=) and the index name
**** Each registered index has an associated column family handle
*** Row deletions must update the appropriate index!
*** API Details
**** Create index
***** operation should be idempotent
**** Delete index
***** remove the registered view functions
***** remove the corresponding column family
**** List indices
**** Query index
***** returns an iterator to return the results as needed
***** results are the output from the app mapping function
***** rows are returned in the same order as the supplied keys array
***** optional keys value to set start/end of results range
***** optional number of rows to skip
***** optional number of rows to limit
**** Build index
***** As a means of constructing the index with existing data
***** Maybe the data was modified externally, for example
**** Index cleanup
***** Called by the application in an ad hoc fashion
***** Delete any column families with our prefix that do not match any registered view
*** Development
**** DONE Initial attempt to define the library API
***** library function: =emit=
****** receives the bytes for the index key (prefix)
****** receives the bytes for the index value
****** application is responsible for serde of the key(prefix) and value
****** library will add the unique suffix to the index key
***** library function: =put=
****** app provides key as bytes and value as trait implementation
****** trait provides =map= and =to_bytes= functions (among others)
****** library will invoke =map= and =to_bytes= before writing to the database
****** library will write key as-is and output of =to_bytes= as the value
****** library will write index entries corresponding to the values emitted
***** trait function: =map=
****** invokes an =emit= function received as a parameter
****** each emitted value is stored as a separate key/value in the index
***** trait function: =to_bytes=
****** this is for the application data, not the index
****** converts the data type a vector of bytes, written to RocksDB as-is
***** trait function: =from_bytes=
****** this is for the application data, not the index
****** converts a vector of bytes (as read from RocksDB) into the data type
****** called by the library when (re)building the index with existing data
****** may return a special error if trait does not serialize this value
**** DONE Consider how =delete= will update the indices
***** this could be what PouchDB refers to as ~stale~ results
***** how to detect stale results?
***** are stale results returned in the scan?
***** would we eagerly remove the stale results?
***** a bloom filter of deleted entries
****** store in the database, probabaly
****** if ID is not in the filter, then it is not deleted
***** prune index of stale entries on scan
***** view iterator could check bloom filter before returning results
**** DONE See some of the PouchDB implementation details
***** =pouchdb/packages/node_modules/pouchdb-abstract-mapreduce/src/index.js=
**** DONE Define the trait(s) and function scaffolding to get the API right
***** maybe the library should manage the RocksDB struct
***** app manages the library struct as it would have the RocksDB struct
***** library would expose common functions: =put=, =get=, =delete=
***** should be able to parameterize the =get= to use a trait function, right?
****** like the =FromStr= trait, it takes an argument and returns a =Self=
****** that way the app gets the exact type deserialized from the bytes
****** indirectly could implement =Default= and then invoke deserialize on it
***** library would provide escape hatch =db()= function to return RocksDB reference
**** DONE Define the mapping of the named indices to the mapping functions
***** library will manage column families
***** pass a set of default instances of the traits to the =new()= call
***** library will add special prefix to the view names
**** DONE Update the index in the put pass-through function
**** DONE Query an index with no key, returns all results
**** DONE Index key must include unique suffix (e.g. ulid)
**** DONE Query must return an iterator that provides index key/value pairs
***** returns (key, value) tuple
***** strip the unique suffix from the index key
**** DONE Serialized index value must include the primary key
**** DONE Query iterator must split document key off of index value
**** DONE Define the API for the library
***** application provides a =Fn= to produce index pairs for any record
****** passed to =Database= constructor
****** is given the key/value pair and an =Emitter=
****** called when building an index
***** a set of view names are registered at startup
***** document trait =map()= receives a =view_name= argument
****** trait will call =emit= if it has something for that view
****** every trait impl gets a chance to emit for every view
****** sort of like PouchDB, just less dynamic
***** in this way, the trait is like a redux reducer
****** every view name passes through every trait's =map()= function
****** only relevant traits will emit anything for the view
***** how to build a single index
****** delete the existing column family, if any, to remove stale entries
****** library reads all records, invokes provided =ByteMapper= function
***** how to define the =view= type to avoid stringly typing, string comparison
****** forget it, just use string for the view name
**** DONE Consider how and when the index will be built
***** do not automatically create the column families on startup
***** upon query, if column family is missing, build the index
***** in =put()=, invoke =map()= with every view for which column family already exists
**** TODO Write test with =put=, =get=, =delete=, =get=, =delete= with index to ensure same behavior as w/o index
**** TODO Write a test where =emit= is given an empty index value
**** TODO Tests to write
***** TODO pass an empty set of views
***** TODO pass a view name that is never used
***** TODO pass an empty view name
***** TODO query on an index for which nothing was ever emitted
**** TODO Query an index with a single key
***** returns only results whose key matches the filter
**** TODO Query an index with multiple keys
***** returns only results whose key matches each of the keys
***** results returned in the same order as the keys
**** TODO Is there a clean way to define and pass the =emit= to the traits?
***** how to streamline the =emit= function call
****** our =emit= is defined as a local closure which is necessary
****** a closure and a =Fn= are not compatible; this is probably impossible
****** see section 19.3 of book on how to define the =Fn= type
**** TODO Remove stale index entries on =delete()=
**** TODO Clean up stale indices
**** TODO Consider options for thread safe operations
*** Publishing
**** TODO Write a guide on how to use properly
***** Define views at time of DB open
***** Prime the indices at startup to improve response time
**** TODO Start a changelog
**** TODO Write API documentation at the module level
***** assumes we already wrote function-level documentation
**** TODO Write a quick example for the =README.md=
**** TODO Write a simple example crate in =examples= directory
**** DONE Populate =Cargo.toml= with useful meta information
**** TODO Push to GitHub
**** TODO Publish to crates.io
*** Further Work
**** TODO Read the LSM key/value stores research paper on secondary index algorithms
***** Has various approaches to implementing indices
** Alternative Databases
*** [[https://github.com/spacejam/sled][sled]] is similar to RocksDB, written in Rust
**** would use their ~keyspace~ in place of column families
**** would use their ID generator in place of ULID or whatever
