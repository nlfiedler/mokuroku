* mokuroku
** Implementation
*** Development
**** TODO Read papers on secondary index strategies
***** DONE Diff-Index: Differentiated Index in Distributed Log-Structured Data Stores
****** Diff-Index stores the primary key after the index key
****** Diff-Index assumes index value is the same as the base value?
******* probably they are doing the index on a single column, so this makes sense
***** DONE Efficient Secondary Attribute Lookup in NoSQL Databases
****** like Diff-Index, assumes index values match readily available data attributes
****** overall performance of "lazy updates" on a stand-alone index is as good as it gets
****** performance is very good with read-heavy workloads
***** TODO Comparative Study of Secondary Indexing Techniques in LSM-based NoSQL Databases
***** c.f. http://dblab.cs.ucr.edu/projects/KeyValueIndexes/
***** current impl is akin to "lazy" updates on a stand-alone index
****** index is stored separately from data (column family)
****** appends new index rows on write
****** merges index rows on query
****** what Diff-Index refers to as ~sync-insert~
***** based on the Efficient Secondary Attribute Lookup in NoSQL Databases paper
****** the secondary index with lazy updates performs pretty well in most cases
****** their embedded index requires modifying LevelDB internal structures
**** DONE Consider defining a database format like HBase
***** HBase uses key, column name, column value
***** Data record key would be key + column name in RocksDB
***** Each index would be on a column, no application code needed
***** Repairing a stale index would be very easy, just look up key+column-name and compare values
***** How then would something like "tags" be written to the database?
****** particularly, how would that be indexed and queried?
***** an interesting idea, but not at all flexible, seems difficult to use
**** DONE Change the format of the index keys and values
**** TODO Update stale index entries on =put()= and =delete()=
***** both =put= and =delete= are the same thing: old index values are stale
***** on update, store primary key in ~mrview--changes~ cf with timestamp value
****** ts would be nanos since epoch, a 16 byte value
****** =let ts: u128 = SystemTime.duration_since(std::time::UNIX_EPOCH)?.as_nanos();=
***** on query, perform "read repair" of updated entries based on timestamp
****** Cassandra does a "read repair" which prunes stale entries on query
***** Diff-Index paper adds index updates to a queue, processes in background
***** some discussions use the term "tombstone" when marking something outdated
***** perhaps maintain a bloom/cuckoo filter of updated primary keys
****** https://github.com/seiflotfy/rust-cuckoofilter
****** https://github.com/nervosnetwork/bloom-filters
****** https://github.com/sagalasan/bloom-filter
***** on startup, scan ~mrview--changes~ to get prime the bloom filter
***** on =query()=, find and remove stale entries, clear deleted rows
**** TODO Write the index key/value pairs received in =put()= using a =WriteBatch=
***** probably should batch up for each column family (index)
**** TODO Write a test that rebuilds the index
**** TODO Add function to delete an index
***** remove corresponding entry from =views= list
**** TODO Clean up stale indices
***** Called by the application in an ad hoc fashion
***** Delete any column families with our prefix that do not match any registered view
**** TODO Support the =rocksdb::WriteBatch= atomic commit feature
**** TODO Using some assumed key/value sizes, compute the overhead of the index, add to README
**** TODO Consider using the KMP algorithm to find the index key separator
***** c.f. https://en.wikipedia.org/wiki/Knuth–Morris–Pratt_algorithm
**** TODO Support query with start and end key values/prefixes
**** TODO Support query options to skip some number of results, limit to some number
**** TODO Consider options for thread safe operations
*** Publishing
**** DONE Write a guide on how to use properly
***** Define views at time of DB open
***** Prime the indices at startup to improve response time
**** DONE Start a changelog
**** DONE Write API documentation at the module level
***** assumes we already wrote function-level documentation
**** DONE Write a quick example for the =README.md=
**** DONE Write a simple example crate in =examples= directory
**** DONE Populate =Cargo.toml= with useful meta information
**** DONE Push to GitHub
**** DONE Publish to crates.io
**** TODO README should have bullet point feature list
***** bring-your-own-format for keys and values
***** emit zero or more index key and values of your design per data record
***** leverage the serialization you are already using with RocksDB
**** TODO Add references to the research papers
*** Further Work
**** TODO Read the LSM key/value stores research paper on secondary index algorithms
***** Has various approaches to implementing indices
**** TODO Support some form of "reduce" operation, like PouchDB
** Alternative Databases
*** [[https://github.com/spacejam/sled][sled]] is similar to RocksDB, written in Rust
**** would use their ~keyspace~ in place of column families
